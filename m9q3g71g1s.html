<div>Consider a classical regression problem, with feature data points represented as a matrix X, and output represented by a vector $y$. There exist a vector of coefficients β such that ŷ=Xβ provides a good estimate for y. We attempted three main regression models to find such a β: Ordinary Least-Squares regression (OLS), Spatial Error Regression (SER), and Random Forest Regression. While OLS merely minimizes the squared sum of the residuals, namely |y-Xβ|2, SER allows for spatial autocorrelation of the dataset and is well-tuned for remote sensing applications.</div><div>Instead of just minimizing the vector u = y-Xβ, we try to filter out the autocorrelation by letting u = ⍴Wu + ε, where ⍴ is a scalar, W is a weight matrix representing the spatial autocorrelation in the dataset, and ε represents the residuals. SER minimizes the autocorrelation of the final residuals.</div><div>Random Forest Regression provides an alternative method of calculating the set of coefficients β. We use a large group of shallow decision trees designed to minimize the mean squared error of the dataset. We implemented each of these regression methods in Python, getting regression coefficients for snow depth and SWE.</div>