<h1 data-label="260031" class="ltx_title_section">Abstract - IAN</h1><div>Features of terrain and vegetation are often used to estimate the distribution of snow within a watershed using statistical modeling approaches, yet little is known of the stability/instability of these models across space, time, and model scale. This is largely due to a lack of the repeated, high-resolution measurements necessary to develop models at multiple points in time, and it inhibits the use of these statistical models in improved water resource forecasts. In this study, we use a novel dataset consisting of gridded, 3m-resolution, LiDAR-derived products depicting elevation, canopy height, canopy density, land cover classification, snow depth, and snow water equivalent (SWE) from the Tuolumne River Basin in California. Each feature is represented by a ~1 GB raster image and roughly 1,500 regressions are run to generate model parameters comparable across a variety of dimensions. Multiple levels of parallelism allow for time-efficient estimation of these models using several existing data analysis packages written in high-level languages. While the parallelism exploited in this analysis is, for the most part, embarrassingly parallel or otherwise fairly straightforward, several challenges emerge when using high-level data analysis languages in a High Performance Computing (HPC) environment. These challenges, as well as the benefits of HPC in these scenarios, are discussed and compared. Our scientific results agree with previous consensus in the dominance of elevation and relative insolation as predictors of snow depth. Furthermore, we show that the importance of elevation decreases sharply moving from late winter to mid-summer, that the importance of insolation peaks in spring, and that feature importance is comparable when predicting snow depth and SWE.&nbsp;</div><h1 data-label="638514" class="ltx_title_section">Introduction - IAN</h1><div>Access to clean, dependable water sources is a  prerequisite for healthy societies, and one-sixth of the worldâ€™s population  depends on snowmelt for this water supply <cite class="ltx_cite raw v1">\cite{Barnett_2005}</cite>. Efficient water use policies and  reservoir operation in snowmelt-driven regions thus depend largely on accurate  predictions of the magnitude and timing of snowmelt. These are both functions  of the spatial distribution of snow water equivalent (SWE), a metric combining  snow depth and density. To date, even the most advanced methods for estimating  snowmelt-driven water supply rely on sparse SWE observations and their  correlations to spring/summer streamflow. By assuming that these correlations  will stay constant into the future, we are implicitly assuming a stationary climate;  however, as climate change warms mountain regions, more winter precipitation  will fall as rain instead of snow, and snow will be confined to higher  elevations, thus altering spatial patterns and rendering these historical point observation-based correlations less useful. Since future SWE distributions may not mirror previous  patterns, there is a growing effort to better observe snow distributions and to improve modeling techniques for interpolating between point observations <cite class="ltx_cite raw v1">\cite{Raleigh_2017,Wrzesien_2017,Cai_2017}</cite>.</div><div>Many such efforts rely on statistical models built on static features of the terrain and vegetation within a given watershed to perform this interpolation <cite class="ltx_cite raw v1">\cite{Geddes_2005}</cite>. This often takes the form of a kriging, or similar, approach; however, little is known of the spatiotemporal stability of these models nor of the effect of model scale (i.e. the resolution at which the terrain and vegetation features are represented). In the case of spatial and temporal nonstationarity, the knowledge gap is largely a function of a lack of data. In order to draw inference on changes in model parameters across years or across dates within a season, a dataset of SWE measurements with (1) a large enough temporal extent to cover these timeframes, (2)  a large enough spatial extent to generate a robust sample representative of the watershed, and (3) a resolution small enough to represent relative features of the terrain (e.g. slope angle) at physically meaningful scales. The recent use of airborne scanning LiDAR for snow depth measurement has made such datasets possible, and the Airborne Snow Observatory (ASO) mission from the Jet Propulsion Laboratory represents the first systematic, repeated snow depth mapping effort over large spatial extents&nbsp;<cite class="ltx_cite raw v1">\cite{Painter_2016}</cite>. When using LiDAR measurements, snow depth is measured directly and is multiplied by observationally-constrained models of snow density to produce maps of SWE. This approach relies on the fact that snow density displays an order of magnitude less spatial variability than snow depth and is thus reasonably well approximated by models&nbsp;<cite class="ltx_cite raw v1">\cite{L_pez_Moreno_2013}</cite>. While ASO SWE estimates provide operationally relevant information to water resource forecasters,&nbsp;water managers, and reservoir operators, it is not, of yet, a scalable method due to high costs of flight time and logistics of the mobile data/compute centers necessary to produce real-time information for each watershed mapped. However, the estimates produced by these flights can be studied to better understand  the degree to which statistical snow depth and SWE models might vary over time.</div><div>To accomplish that goal, we apply two simple yet commonly used <cite class="ltx_cite raw v1">\cite{L_pez_Moreno_2005,Jonas_2009}</cite> regression approaches to the gridded snow depth and SWE timeseries provided by ASO fli, relying on underlying raster images of land cover class, canopy height, canopy density, elevation, and several terrain-relevant transformations of the elevation raster as features. These two approaches are a Spatial Error Model - which takes the form of an Generalized Least Squares regression for which the error term has a spatial autoregressive structure - and a Random Forest. To understand changes in model structure over time, we leverage the National Center for Atmospheric Research (NCAR)'s distributed computing resources to perform these regressions on 44 different "snapshots" of snow depth and SWE at different dates during the late Winter to early Summer range, across 2013 through 2016. To understand the impact of model scale, we repeat each model at 7 different model resolutions. In total, we execute &gt;1,500 regression models. We compare the changing importance of individual features with "feature importance" metrics and assess the operational significance of temporal model nonstationarity by comparing the root mean squared error (RMSE) of models trained on one snow depth/SWE from one date and tested on another. Spatial nonstationarity, while an integral part of the larger analysis, is beyond the scope of this report.</div><div>In the remainder of this report, we (1) describe the computing resources used for this analysis; (2) outline the methods used for data preprocessing and for running the two regressions; (3) discuss the levels of parallelism exploited, as well as the challenges encountered; (4) and (5) provide the scientific and performance results of the analysis; (6) discuss the meaning of the scientific results; and (7) conclude with a discussion of the operational value of these results and a description of the next steps in this research project.</div><h1>Computing Resources - VARUN</h1><div></div>