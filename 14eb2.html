<h3 data-label="990860" class="ltx_title_subsubsection">Cropping and Resampling</h3><div>For steps one and two, each of the 121 raw raster images (39 snapshots of snow depth at 3m, 39 snapshots of snow depth at 50m, 39 snapshots of SWE at 50m, and 4 snowoff rasters) was given assigned to a batch job in which it was first cropped and corrected and then resampled to 3 lower resolutions. 3m snowon data (snow depth and SWE) were resampled to 10, 30, and 50m. 50m snowon data was resampled to 100, 300, and 500m. 50m data was thus obtained both via raw rasters and via resampled 3m rasters to facilitate validation of our resampling techniques. In the case of snowoff rasters, since these were only provided at 3m, they were resampled to 10, 30, 50, 100, 300, and 500m. Node memory constraints in the Yellowstone cluster, where the majority of our core-hour allocation was located, prevented full CPU utilization for cropping and resampling of the 3m images. Thus, a parallelization strategy was devised such that one job was submitted for cropping and resampling the 3m rasters, using 8 CPUs per node and a separate was submitted for cropping and resampling the 50m rasters, in which all 16 CPUs per node were allocated a raster to process. The parallel processing was invoked using NCAR's "command file" framework, which allows for flexible Multiple Program Multiple Data (MPMD) parallelism as long as each "command" is independent. We were using a SPMD approach, so did not need this extra flexibility, but this framework provided a very simple way to pass multiple files to a given subroutine. This means that the path to a file with one command per line is passed as an argument to the batch submission script. mpirun is then called with&nbsp;</div><h3 data-label="148321" class="ltx_title_subsubsection">DEM Transformations</h3><div></div>